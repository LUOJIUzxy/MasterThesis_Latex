% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

\section{Background and Motivation}
Portfolio optimization has been a cornerstone of financial decision-making since its formal introduction in the mid-20th century. The seminal work of Harry Markowitz in 1952 laid the foundation for \ac{MPT}, which introduced the concepts of mean-variance optimization and the efficient frontier. This work transformed the way investors approached asset allocation by providing a rigorous mathematical framework to balance risk and return. Over the decades, \ac{MPT} evolved through the development of models such as the \ac{CAPM}, single-index models, and risk-parity approaches. These models addressed various practical challenges, such as the estimation of covariance matrices and the inclusion of downside risk measures.

However, traditional portfolio optimization methods often rely on strong assumptions, such as the normality of asset returns and the stability of their relationships over time. In reality, financial markets are highly complex, characterized by non-linear interactions, non-stationary behaviors, and abrupt regime changes. The limitations of classical methods in capturing these dynamics have spurred the integration of advanced computational techniques, including \ac{ML}, into the field of portfolio management.

Machine learning, with its ability to model non-linear patterns and process large datasets, has emerged as a powerful tool for financial forecasting. Gaussian Process Regression (GPR), a Bayesian non-parametric approach, has gained attention for its probabilistic nature and flexibility in modeling uncertainty. These attributes make \ac{GPR} particularly well-suited for predicting asset returns and volatilities, critical inputs for portfolio optimization.

Despite the advancements in \ac{ML} and the promise of techniques like \ac{GPR}, significant challenges remain. Accurately forecasting asset returns is notoriously difficult due to the inherent volatility and unpredictability of financial markets. Traditional methods of estimating parameters, such as volatility and correlations, often fall short during periods of market stress, where accurate predictions are most needed. This study aims to bridge these gaps by integrating \ac{GPR} into a dynamic portfolio optimization framework, leveraging its predictive strengths to enhance decision-making in uncertain and rapidly changing markets.

\section{Research Objectives}
The primary objective of this research is to develop and evaluate a portfolio optimization framework that combines the predictive capabilities of GPR with strategic asset allocation. The study focuses on improving investment performance by addressing the shortcomings of traditional methods and integrating probabilistic predictions into decision-making. Specifically, the research aims to:

Construct \ac{GPR} models capable of forecasting the returns and volatilities of selected assets with a high degree of accuracy. The models will be updated iteratively to incorporate new data and adapt to market changes dynamically.

Design portfolio optimization strategies that utilize \ac{GPR} outputs, including traditional approaches like Maximum Return, Minimum Volatility, and Maximum Sharpe Ratio, as well as a novel Dynamic Strategy. The latter incorporates \ac{GPR}'s probabilistic forecasts to determine optimal reallocation decisions based on threshold probabilities.

Implement a comprehensive backtesting framework to evaluate the strategies' performance over historical market data, accounting for transaction costs and realistic market conditions.

Demonstrate the practical applicability of the Dynamic Strategy by analyzing its risk-return trade-offs, adaptability, and cost efficiency compared to traditional strategies.

Through these objectives, the study seeks to contribute to the field of predictive portfolio optimization by presenting a robust and practical approach to integrating advanced forecasting methods into asset management.

\subsection{Role of machine learning in financial forecasting}
\ac{ML} has gained significant traction in financial markets due to its ability to analyze vast amounts of data and identify complex patterns that traditional models may overlook.
In particular, \ac{GPR} has emerged as a powerful tool for time-series forecasting, offering a flexible framework for capturing non-linear relationships and uncertainty in predictions.

\subsection{Challenges in time-series forecasting and traditional portfolio optimization methods}
Despite the advancements in \ac{ML} techniques, predicting asset returns remains a challenging task due to the inherent volatility and non-stationarity of financial markets.
Moreover, traditional portfolio optimization methods, while theoretically elegant, often face significant practical challenges in implementation. These challenges primarily stem from the difficulty in accurately estimating input parameters and the inherent uncertainty in financial time-series forecasting. 
This section examines these challenges and introduces how \ac{GPR} provides a novel approach to addressing them.

\paragraph{Parameter Estimation Challenges in Modern Portfolio Theory}
Modern Portfolio Theory (MPT), while foundational in the field of finance, is critically dependent on the accurate estimation of several key parameters, making its practical application challenging. Among these, volatility estimation stands out as the most pivotal yet problematic aspect of portfolio optimization. Traditional methods for estimating volatility typically rely on historical data under the assumption that past patterns will persist into the future. However, this assumption is often flawed, as financial markets are inherently dynamic and subject to frequent regime changes, fluctuating volatility clusters, and intricate interdependencies. These characteristics render historical volatility estimates backward-looking and overly sensitive to the chosen estimation window, potentially resulting in misleading inputs for portfolio construction. Furthermore, the presence of heteroskedasticity in financial time series complicates volatility estimation, as periods of stable and erratic market behavior frequently alternate.

The challenges of parameter estimation in \ac{MPT} extend beyond volatility. Expected returns, another critical input, are notoriously difficult to predict with accuracy. They are highly sensitive to estimation errors, which can significantly skew portfolio outcomes. Additionally, expected returns exhibit a time-varying nature, influenced by changing market regimes and economic conditions. This variability further complicates reliable estimation and introduces additional layers of uncertainty into the optimization process.

Another significant hurdle in MPT is accurately capturing the correlation structure among assets. Correlations are dynamic and often shift dramatically during periods of market stress, precisely when understanding interdependencies is most crucial. Relying on static historical correlations can lead to underestimation of risks and suboptimal diversification. Moreover, as the number of assets in a portfolio increases, the complexity of estimating a stable and meaningful correlation matrix grows quadratically, creating what is commonly referred to as the "curse of dimensionality." This issue is compounded by computational challenges in managing high-dimensional datasets, further straining the practical applicability of MPT.

These challenges collectively highlight the limitations of traditional approaches in addressing the dynamic and complex nature of financial markets. Volatility, expected returns, and correlation structures, while central to the theoretical framework of MPT, require sophisticated methods and adaptive modeling techniques to ensure their reliability and relevance in real-world applications. Addressing these limitations is critical for advancing portfolio optimization practices and improving their alignment with the realities of modern financial systems.

\paragraph{Limitations of Traditional Forecasting Methods}
Traditional forecasting approaches in finance have predominantly relied on methods that provide point estimates, failing to capture the inherent uncertainty in financial predictions. These methods often make strong assumptions about the underlying data distribution and struggle to adapt to the non-linear, non-stationary nature of financial time series. \ac{ARIMA} models, exponential smoothing, and other classical approaches, while mathematically tractable, often fall short in capturing the complex dynamics of financial markets.

A fundamental limitation of these traditional approaches is their rigidity in handling uncertainty. Point forecasts, even when accompanied by confidence intervals based on historical volatility, fail to capture the dynamic nature of prediction uncertainty. This limitation becomes particularly problematic in portfolio optimization, where understanding the reliability of forecasts is as important as the forecasts themselves.

Conventional approaches to financial time-series forecasting exhibit several limitations:

Traditional methods often provide single-point forecasts, which lack uncertainty quantification and have limited ability to capture prediction confidence. This results in insufficient information for risk management.

Model rigidity is another issue, as it involves the assumption of specific probability distributions, difficulty in capturing non-linear relationships, limited adaptation to changing market conditions, and oversimplification of complex market dynamics.

Data requirements pose additional challenges, including the need for large historical datasets, sensitivity to outliers and noise, the challenge of incorporating multiple data sources, and difficulty in handling missing data.

\paragraph{Advantages of Gaussian Process Regression}
Our research proposes \ac{GPR} as a solution to these challenges, offering several key advantages:

\begin{enumerate}
    \item \textbf{Probabilistic Framework}
    \begin{itemize}
        \item Natural uncertainty quantification
        \item Automatic volatility estimation through posterior variance
        \item Capture of prediction confidence intervals
        \item Robust handling of noise in financial data
    \end{itemize}

    \item \textbf{Flexible Modeling}
    \begin{itemize}
        \item Non-parametric approach avoiding distributional assumptions
        \item Ability to capture complex non-linear relationships
        \item Automatic complexity adjustment through kernel selection
        \item Incorporation of prior knowledge through kernel design
    \end{itemize}

    \item \textbf{Parameter Estimation}
    \begin{itemize}
        \item Direct modeling of volatility through posterior variance
        \item Joint estimation of returns and risk
        \item Principled handling of uncertainty
        \item Adaptive to changing market conditions
    \end{itemize}
\end{enumerate}

\paragraph{Addressing Traditional Limitations}
Our \ac{GPR}-based approach specifically addresses the key limitations of \ac{MPT}:

\begin{equation}
    \sigma_{GPR}^2(x_*) = k(x_*, x_*) - k(x_*, X)[K(X,X) + \sigma_n^2I]^{-1}k(X, x_*)
    \label{eq:gpr_variance}
\end{equation}

Where $\sigma_{GPR}^2(x_*)$ represents the posterior variance at prediction point $x_*$, providing a direct estimate of volatility that:

\begin{itemize}
    \item Naturally accounts for uncertainty in predictions
    \item Adapts to local data density and quality
    \item Provides time-varying volatility estimates
    \item Incorporates both local and global market information
\end{itemize}

The \ac{GPR} approach offers several fundamental advantages over traditional methods. Unlike historical volatility estimates that require arbitrary window selection, \ac{GPR}'s volatility estimates emerge naturally from the probabilistic learning process. The method adapts automatically to different market regimes through its kernel function, which can capture both long-term trends and short-term fluctuations in market behavior.

Furthermore, \ac{GPR}'s non-parametric nature frees it from restrictive assumptions about return distributions. The method can capture complex, non-linear patterns in the data while maintaining the ability to quantify uncertainty in its predictions. This combination of flexibility and uncertainty awareness makes it particularly well-suited for financial applications where both accuracy and risk assessment are crucial.


\paragraph{Implications for Portfolio Optimization}
The \ac{GPR} framework transforms the traditional portfolio optimization problem by:
The integration of \ac{GPR} into portfolio optimization transforms the traditional \ac{MPT} framework by providing more reliable and dynamic parameter estimates. By directly modeling the uncertainty in our predictions, we can make more informed portfolio allocation decisions that account for both expected returns and our confidence in those expectations. This approach naturally leads to more robust portfolios that adapt to changing market conditions while maintaining a principled approach to risk management.

The significance of this advancement cannot be overstated. By addressing one of the fundamental criticisms of \ac{MPT} - the difficulty of accurately estimating volatility - our \ac{GPR}-based approach bridges the gap between theoretical elegance and practical applicability. This enhancement makes \ac{MPT} more reliable and useful for real-world portfolio management, where accurate risk assessment is crucial for maintaining stable, long-term investment performance.



\section{Thesis Structure}
The thesis is organized as follows: Chapter 2 reviews the relevant literature, covering portfolio optimization theories, Gaussian Process Regression, and the integration of machine learning in finance. Chapter 3 outlines the methodology, detailing the data collection, model development, and strategy design processes. Chapter 4 presents the results of the backtesting framework, comparing the performance of the proposed strategies. Chapter 5 discusses the implications of the findings, addressing practical applications and limitations. Finally, Chapter 6 concludes with a summary of key insights and suggestions for future research.
